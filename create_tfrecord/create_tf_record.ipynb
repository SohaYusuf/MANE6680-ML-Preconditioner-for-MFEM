{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6bfce33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 01:25:55.597881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0216 01:25:57.462451 140735516593776 module_wrapper.py:139] From /tmp/ipykernel_192182/707491456.py:8: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from np_to_tfrecord import np_to_tfrecords\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from SolvePossion_FD import *\n",
    "import os\n",
    "import json\n",
    "import functools\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfc7e3",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be509377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A,b,coordinates,errors,labels = main(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f944a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8778e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_type = np.int64\n",
    "time_steps = 3\n",
    "no_of_nodes = 25\n",
    "no_of_cells = 32\n",
    "\n",
    "cells = np.ones((1,no_of_cells,3), dtype=int_type)\n",
    "mesh_pos = np.ones((1,no_of_nodes,2), dtype=np.float32)\n",
    "node_type = np.ones((1,no_of_nodes,1), dtype=int_type)\n",
    "temperature = np.zeros((time_steps,no_of_nodes,1), dtype=np.float32)\n",
    "\n",
    "cells[None,:,:] = np.array([\n",
    "    [0, 1, 6],\n",
    "    [1, 2, 7],\n",
    "    [2, 3, 8],\n",
    "    [3, 4, 9],\n",
    "    [5, 6, 11],\n",
    "    [6, 7, 12],\n",
    "    [7, 8, 13],\n",
    "    [8, 9, 14],\n",
    "    [10, 11, 16],\n",
    "    [11, 12, 17],\n",
    "    [12, 13, 18],\n",
    "    [13, 14, 19],\n",
    "    [15, 16, 21],\n",
    "    [16, 17, 22],\n",
    "    [17, 18, 23],\n",
    "    [18, 19, 24],\n",
    "    [0, 6, 5],\n",
    "    [1, 7, 6],\n",
    "    [2, 8, 7],\n",
    "    [3, 9, 8],\n",
    "    [5, 11, 10],\n",
    "    [6, 12, 11],\n",
    "    [7, 13, 12],\n",
    "    [8, 14, 13],\n",
    "    [10, 16, 15],\n",
    "    [11, 17, 16],\n",
    "    [12, 18, 17],\n",
    "    [13, 19, 18],\n",
    "    [15, 21, 20],\n",
    "    [16, 22, 21],\n",
    "    [17, 23, 22],\n",
    "    [18, 24, 23]\n",
    "], dtype=int_type)\n",
    "\n",
    "\n",
    "mesh_pos[None,:,:] = coordinates\n",
    "\n",
    "node_type[None,:,:] = np.array([\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [6],\n",
    "    [6],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [6],\n",
    "    [6],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    [6],\n",
    "    \n",
    "], dtype = int_type)\n",
    "\n",
    "labels = labels.astype(np.float32)\n",
    "t0 = np.array([\n",
    "    [labels[0]],\n",
    "    [labels[1]],\n",
    "    [labels[2]],\n",
    "    [labels[3]],\n",
    "    [labels[4]],\n",
    "    [labels[5]],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [labels[9]],\n",
    "    [labels[10]],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [labels[14]],\n",
    "    [labels[15]],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [labels[19]],\n",
    "    [labels[20]],\n",
    "    [labels[21]],\n",
    "    [labels[22]],\n",
    "    [labels[23]],\n",
    "    [labels[24]],\n",
    "    \n",
    "], dtype = np.float32)\n",
    "\n",
    "t1 = labels\n",
    "\n",
    "temperature[1,:,:] = t0\n",
    "temperature[2,:,:] = t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d907495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cells_shape', cells.shape, 'cells_dtype ', cells.dtype)\n",
    "print('mesh_pos', mesh_pos.shape, 'mesh_pos_dtype ', mesh_pos.dtype)\n",
    "print('node_type', node_type.shape, 'node_type_dtype ', node_type.dtype)\n",
    "print('temperature', temperature.shape, 'temperature_dtype ', temperature.dtype)\n",
    "#print('temperature', len(temperature), 'temperature_dtype ', type(temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f0690",
   "metadata": {},
   "source": [
    "# Write TF Record File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tfrecords(data, output_file):\n",
    "    \n",
    "    # write records to a tfrecords file\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "    \n",
    "    for i in range(len(data['temperature'])):\n",
    "        feature = {}\n",
    "        # Loop through all the features you want to write\n",
    "        for name, value in data.items():\n",
    "#           if name=='temperature':\n",
    "#               value = value[i]\n",
    "          # Feature contains a map of string to feature proto objects\n",
    "          if value.dtype == \"float32\":\n",
    "            #feature[name] = tf.train.Feature(float_list=tf.train.FloatList(value=value.flatten()))\n",
    "            feature[name] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.flatten().tobytes()]))\n",
    "          elif value.dtype == \"int32\" or value.dtype == \"int64\":\n",
    "            #feature[name] = tf.train.Feature(int64_list=tf.train.Int64List(value=value.flatten()))\n",
    "            feature[name] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.flatten().tobytes()]))\n",
    "          else:\n",
    "              raise ValueError('invalid data format: '+str(value.dtype))\n",
    "        \n",
    "        # Construct the Example proto object\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        # print(example)\n",
    "    \n",
    "        # Serialize the example to a string\n",
    "        serialized = example.SerializeToString()\n",
    "    \n",
    "        # write the serialized objec to the disk\n",
    "        writer.write(serialized)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'cells':cells,\n",
    "    'mesh_pos':mesh_pos,\n",
    "    'node_type':node_type,\n",
    "    'temperature':temperature\n",
    "}\n",
    "\n",
    "file_path = \"/gpfs/u/scratch/ODLC/ODLCsfsh/deepmind-research_soha/meshgraphnets/data/cylinder_flow\"\n",
    "# os.remove(file_path)\n",
    "# np_to_tfrecords(data, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee1cc2",
   "metadata": {},
   "source": [
    "# Read TF Record file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b20893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse(proto,meta):\n",
    "#     return tf.parse_single_example(proto, features={\n",
    "#        'cells': tf.FixedLenFeature([1,32,3], tf.int64, default_value=tf.zeros((1,32,3),dtype=tf.int64)),\n",
    "#        'mesh_pos': tf.FixedLenFeature([1,25,2], tf.float32, default_value=tf.zeros((1,25,2),dtype=tf.float32)),\n",
    "#        'node_type': tf.FixedLenFeature([1,25,1], tf.int64, default_value=tf.zeros((1,25,1),dtype=tf.int64)),\n",
    "#        'temperature': tf.FixedLenFeature([2,25,1], tf.float32, default_value=tf.zeros((2,25,1),dtype=tf.float32)),\n",
    "#    })\n",
    "\n",
    "# def parse(proto,meta):\n",
    "#     return tf.parse_single_example(proto, features={\n",
    "#        'cells': tf.io.VarLenFeature(tf.int64),\n",
    "#        'mesh_pos': tf.io.VarLenFeature(tf.float32),\n",
    "#        'node_type': tf.io.VarLenFeature(tf.int64),\n",
    "#        'temperature': tf.io.VarLenFeature(tf.float32)\n",
    "#    })\n",
    "\n",
    "\n",
    "def parse(proto,meta):\n",
    "    features = tf.parse_single_example(proto, features={\n",
    "       'cells': tf.io.VarLenFeature(tf.int64),\n",
    "       'mesh_pos': tf.io.VarLenFeature(tf.float32),\n",
    "       'node_type': tf.io.VarLenFeature(tf.int64),\n",
    "       'temperature': tf.io.VarLenFeature(tf.float32)\n",
    "    })\n",
    "    out = {}\n",
    "    print(features['temperature'].shape)\n",
    "    for key, field in meta['features'].items():\n",
    "        data = features[key].values\n",
    "        data = tf.reshape(data, field['shape'])\n",
    "        if field['type'] == 'static':\n",
    "            data = tf.tile(data, [meta['trajectory_length'], 1, 1])\n",
    "        elif field['type'] != 'dynamic':\n",
    "            raise ValueError('invalid data format')\n",
    "        out[key]=data\n",
    "    \n",
    "    return out\n",
    "\n",
    "def _parse_function(proto, meta):\n",
    "  keys_to_features = {}\n",
    "  for key, feature in meta[\"features\"].items():\n",
    "        data = tf.io.FixedLenFeature(feature[\"shape\"], getattr(tf, feature['dtype']))\n",
    "        keys_to_features[key] = data\n",
    "#         if key=='temperature':\n",
    "#             data = tf.io.FixedLenFeature([1,25,1], getattr(tf, feature['dtype']))\n",
    "#         else:\n",
    "            \n",
    "  parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "  out = {}\n",
    "  for key, feature in meta[\"features\"].items():\n",
    "      data = parsed_features[key]\n",
    "      if feature['type'] == 'static':\n",
    "          data = tf.tile(data, [meta['trajectory_length'], 1, 1])\n",
    "      elif feature['type'] != 'dynamic':\n",
    "          raise ValueError('invalid data format')\n",
    "      out[key] = data\n",
    "  return out\n",
    "\n",
    "\n",
    "def _parse(proto, meta):\n",
    "  \"\"\"Parses a trajectory from tf.Example.\"\"\"\n",
    "  feature_lists = {k: tf.io.VarLenFeature(tf.string)\n",
    "                   for k in meta['field_names']}\n",
    "  features = tf.io.parse_single_example(proto, feature_lists)\n",
    "  out = {}\n",
    "  for key, field in meta['features'].items():\n",
    "    data = tf.io.decode_raw(features[key].values, getattr(tf, field['dtype']))\n",
    "    data = tf.reshape(data, field['shape'])\n",
    "    if field['type'] == 'static':\n",
    "      data = tf.tile(data, [meta['trajectory_length'], 1, 1])\n",
    "    elif field['type'] == 'dynamic_varlen':\n",
    "      length = tf.io.decode_raw(features['length_'+key].values, tf.int32)\n",
    "      length = tf.reshape(length, [-1])\n",
    "      data = tf.RaggedTensor.from_row_lengths(data, row_lengths=length)\n",
    "    elif field['type'] != 'dynamic':\n",
    "      raise ValueError('invalid data format')\n",
    "    out[key] = data\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, split):\n",
    "  \"\"\"Load dataset.\"\"\"\n",
    "  with open(os.path.join(path, 'meta.json'), 'r') as fp:\n",
    "    meta = json.loads(fp.read())\n",
    "  ds = tf.data.TFRecordDataset(os.path.join(path, split+'.tfrecord'))\n",
    "  print('ds: ',ds)\n",
    "  ds = ds.map(functools.partial(_parse, meta=meta), num_parallel_calls=8)\n",
    "  # ds = ds.prefetch(1)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "dataset = load_dataset(file_path, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8fc50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "positions = next(iterator)\n",
    "print()\n",
    "print(positions)\n",
    "arrays = [np.array(positions[item]) for item in positions]\n",
    "for array in arrays:\n",
    "    print(array.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
